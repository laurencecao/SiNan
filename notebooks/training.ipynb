{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\ude80 FunctionGemma \u4ea4\u4e92\u5f0f\u8bad\u7ec3 Notebook\n",
        "\n",
        "\u672c Notebook \u63d0\u4f9b\u53ef\u89c6\u5316\u7684\u6a21\u578b\u5fae\u8c03\u73af\u5883\uff0c\u652f\u6301\uff1a\n",
        "- \ud83d\udcca \u5b9e\u65f6\u8bad\u7ec3\u6307\u6807\u53ef\u89c6\u5316\n",
        "- \ud83c\udfaf \u4ea4\u4e92\u5f0f\u53c2\u6570\u914d\u7f6e\n",
        "- \ud83d\udcc8 Loss \u66f2\u7ebf\u52a8\u6001\u7ed8\u5236\n",
        "- \ud83d\udd0d \u8bad\u7ec3\u6837\u672c\u8d28\u91cf\u68c0\u67e5\n",
        "- \ud83d\udcbe \u6a21\u578b\u5bfc\u51fa\u4e0e\u63a8\u7406\u6d4b\u8bd5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. \u73af\u5883\u521d\u59cb\u5316"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u68c0\u67e5 GPU \u53ef\u7528\u6027\n",
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# \u6dfb\u52a0\u9879\u76ee\u6839\u76ee\u5f55\u5230\u8def\u5f84\n",
        "project_root = Path().absolute().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"\ud83d\udd25 PyTorch \u7248\u672c: {torch.__version__}\")\n",
        "print(f\"\ud83c\udfae CUDA \u53ef\u7528: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\ud83d\udcfa GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"\ud83d\udcbe GPU \u663e\u5b58: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f \u8b66\u544a: \u672a\u68c0\u6d4b\u5230 GPU\uff0c\u8bad\u7ec3\u5c06\u975e\u5e38\u6162\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. \u5bfc\u5165\u4f9d\u8d56"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from tqdm.notebook import tqdm\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# \u9879\u76ee\u6a21\u5757\n",
        "from src.utils.config_loader import load_config, print_config\n",
        "from src.data_engine.converter import DataConverter\n",
        "from src.data_engine.formatter import FunctionGemmaFormatter\n",
        "from src.training.trainer import FunctionGemmaTrainer\n",
        "from src.training.callbacks import (\n",
        "    WandbCallback,\n",
        "    SampleGenerationCallback,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# \u8bbe\u7f6e\u65e5\u5fd7\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"\u2705 \u6240\u6709\u4f9d\u8d56\u5bfc\u5165\u6210\u529f\uff01\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. \u4ea4\u4e92\u5f0f\u53c2\u6570\u914d\u7f6e\n",
        "\n",
        "\u4f7f\u7528\u4e0b\u9762\u7684\u63a7\u4ef6\u914d\u7f6e\u8bad\u7ec3\u53c2\u6570\uff1a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u521b\u5efa\u4ea4\u4e92\u5f0f\u914d\u7f6e\u63a7\u4ef6\n",
        "config_widgets = {\n",
        "    'model_name': widgets.Text(\n",
        "        value='google/functiongemma-270m-it',\n",
        "        description='\u6a21\u578b\u540d\u79f0:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'max_seq_length': widgets.IntSlider(\n",
        "        value=2048, min=512, max=8192, step=512,\n",
        "        description='\u6700\u5927\u5e8f\u5217\u957f\u5ea6:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'lora_rank': widgets.IntSlider(\n",
        "        value=16, min=4, max=64, step=4,\n",
        "        description='LoRA Rank:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'lora_alpha': widgets.IntSlider(\n",
        "        value=16, min=4, max=64, step=4,\n",
        "        description='LoRA Alpha:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'epochs': widgets.IntSlider(\n",
        "        value=3, min=1, max=10, step=1,\n",
        "        description='\u8bad\u7ec3\u8f6e\u6570:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'batch_size': widgets.IntSlider(\n",
        "        value=4, min=1, max=16, step=1,\n",
        "        description='Batch Size:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'learning_rate': widgets.FloatLogSlider(\n",
        "        value=2e-4, base=10, min=-5, max=-3, step=0.1,\n",
        "        description='\u5b66\u4e60\u7387:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'gradient_accumulation': widgets.IntSlider(\n",
        "        value=4, min=1, max=16, step=1,\n",
        "        description='\u68af\u5ea6\u7d2f\u79ef:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'data_path': widgets.Text(\n",
        "        value='data/processed/train.jsonl',\n",
        "        description='\u6570\u636e\u8def\u5f84:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'output_dir': widgets.Text(\n",
        "        value=f'outputs/models/experiment_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
        "        description='\u8f93\u51fa\u76ee\u5f55:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "}\n",
        "\n",
        "# \u663e\u793a\u914d\u7f6e\u63a7\u4ef6\n",
        "print(\"\ud83c\udf9b\ufe0f \u8bad\u7ec3\u53c2\u6570\u914d\u7f6e\")\n",
        "print(\"=\" * 50)\n",
        "for widget in config_widgets.values():\n",
        "    display(widget)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. \u6570\u636e\u52a0\u8f7d\u4e0e\u53ef\u89c6\u5316"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_visualize_data(data_path: str):\n",
        "    data_path = Path(data_path)\n",
        "    \n",
        "    if not data_path.exists():\n",
        "        print(f\"\u26a0\ufe0f \u6570\u636e\u6587\u4ef6\u4e0d\u5b58\u5728: {data_path}\")\n",
        "        print(\"\u6b63\u5728\u521b\u5efa\u793a\u4f8b\u6570\u636e...\")\n",
        "        create_sample_data(data_path)\n",
        "    \n",
        "    converter = DataConverter()\n",
        "    dataset = converter.load_dataset(str(data_path))\n",
        "    df = pd.DataFrame(dataset)\n",
        "    \n",
        "    print(f\"\\n\ud83d\udcca \u6570\u636e\u6982\u89c8\")\n",
        "    print(f\"\u603b\u6837\u672c\u6570: {len(df)}\")\n",
        "    print(f\"\u5217\u540d: {list(df.columns)}\")\n",
        "    \n",
        "    print(\"\\n\ud83d\udccb \u524d 3 \u6761\u6837\u672c:\")\n",
        "    for i in range(min(3, len(df))):\n",
        "        print(f\"\\n\u6837\u672c {i+1}:\")\n",
        "        for col in df.columns:\n",
        "            value = df.iloc[i][col]\n",
        "            if isinstance(value, str) and len(value) > 200:\n",
        "                value = value[:200] + \"...\"\n",
        "            print(f\"  {col}: {value}\")\n",
        "    \n",
        "    return dataset, df\n",
        "\n",
        "def create_sample_data(output_path: Path):\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    sample_data = [\n",
        "        {\"text\": \"Sample training text 1\"},\n",
        "        {\"text\": \"Sample training text 2\"},\n",
        "        {\"text\": \"Sample training text 3\"},\n",
        "    ]\n",
        "    \n",
        "    expanded_data = []\n",
        "    for i in range(100):\n",
        "        for sample in sample_data:\n",
        "            expanded_data.append(sample)\n",
        "    \n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for item in expanded_data:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "    \n",
        "    print(f\"\u2705 \u5df2\u521b\u5efa\u793a\u4f8b\u6570\u636e: {output_path}\")\n",
        "\n",
        "# \u52a0\u8f7d\u6570\u636e\n",
        "data_path = config_widgets['data_path'].value\n",
        "dataset, df = load_and_visualize_data(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. \u6570\u636e\u7edf\u8ba1\u5206\u6790"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u6570\u636e\u7edf\u8ba1\u53ef\u89c6\u5316\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "if 'text' in df.columns:\n",
        "    text_lengths = df['text'].str.len()\n",
        "    axes[0].hist(text_lengths, bins=30, edgecolor='black', alpha=0.7)\n",
        "    axes[0].set_xlabel('Text Length')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title('Distribution of Text Length')\n",
        "    axes[0].axvline(text_lengths.mean(), color='red', linestyle='--')\n",
        "\n",
        "if 'tool_name' in df.columns:\n",
        "    tool_counts = df['tool_name'].value_counts()\n",
        "    tool_counts.plot(kind='bar', ax=axes[1])\n",
        "    axes[1].set_title('Tool Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\ud83d\udcc8 \u6570\u636e\u7edf\u8ba1\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. \u8bad\u7ec3\u53ef\u89c6\u5316\u56de\u8c03\u7c7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "from collections import defaultdict\n",
        "\n",
        "class JupyterVisualizationCallback(TrainerCallback):\n",
        "    def __init__(self, update_steps: int = 10):\n",
        "        super().__init__()\n",
        "        self.update_steps = update_steps\n",
        "        self.metrics_history = defaultdict(list)\n",
        "        self.fig = None\n",
        "        self.axes = None\n",
        "    \n",
        "    def setup_plot(self):\n",
        "        plt.ion()\n",
        "        self.fig, self.axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "        self.fig.suptitle('Training Metrics (Real-time)', fontsize=14)\n",
        "        plt.show()\n",
        "    \n",
        "    def on_train_begin(self, args, state, control, **kwargs):\n",
        "        print(\"\\n\ud83d\ude80 \u8bad\u7ec3\u5f00\u59cb\uff01\")\n",
        "        self.setup_plot()\n",
        "    \n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is None:\n",
        "            return\n",
        "        step = state.global_step\n",
        "        for key, value in logs.items():\n",
        "            if isinstance(value, (int, float)):\n",
        "                self.metrics_history[key].append((step, value))\n",
        "        if step % self.update_steps == 0:\n",
        "            self.update_plots()\n",
        "    \n",
        "    def update_plots(self):\n",
        "        if self.axes is None:\n",
        "            return\n",
        "        for ax in self.axes.flat:\n",
        "            ax.clear()\n",
        "        \n",
        "        if 'loss' in self.metrics_history:\n",
        "            steps, losses = zip(*self.metrics_history['loss'])\n",
        "            self.axes[0, 0].plot(steps, losses, 'b-', linewidth=2)\n",
        "            self.axes[0, 0].set_title('Training Loss')\n",
        "            self.axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        self.fig.canvas.draw()\n",
        "        self.fig.canvas.flush_events()\n",
        "        plt.pause(0.01)\n",
        "    \n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        print(\"\\n\u2705 \u8bad\u7ec3\u5b8c\u6210\uff01\")\n",
        "        plt.ioff()\n",
        "        plt.savefig('training_metrics.png', dpi=150)\n",
        "\n",
        "print(\"\u2705 \u53ef\u89c6\u5316\u56de\u8c03\u7c7b\u5df2\u5b9a\u4e49\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. \u5f00\u59cb\u8bad\u7ec3\n",
        "\n",
        "\u8fd0\u884c\u4e0b\u9762\u7684\u5355\u5143\u683c\u5f00\u59cb\u8bad\u7ec3\uff1a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from omegaconf import OmegaConf\n",
        "\n",
        "config_dict = {\n",
        "    'model': {\n",
        "        'name': config_widgets['model_name'].value,\n",
        "        'max_seq_length': config_widgets['max_seq_length'].value,\n",
        "        'dtype': 'bfloat16',\n",
        "        'lora': {\n",
        "            'enabled': True,\n",
        "            'rank': config_widgets['lora_rank'].value,\n",
        "            'alpha': config_widgets['lora_alpha'].value,\n",
        "            'target_modules': [\"q_proj\", \"k_proj\", \"v_proj\"],\n",
        "        },\n",
        "    },\n",
        "    'training': {\n",
        "        'epochs': config_widgets['epochs'].value,\n",
        "        'per_device_train_batch_size': config_widgets['batch_size'].value,\n",
        "        'learning_rate': config_widgets['learning_rate'].value,\n",
        "    },\n",
        "    'logging': {\n",
        "        'output_dir': config_widgets['output_dir'].value,\n",
        "        'wandb': {'enabled': False}\n",
        "    }\n",
        "}\n",
        "\n",
        "config = OmegaConf.create(config_dict)\n",
        "print(\"\ud83d\udd27 \u8bad\u7ec3\u914d\u7f6e\")\n",
        "print(OmegaConf.to_yaml(config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u521b\u5efa\u8bad\u7ec3\u5668\n",
        "trainer = FunctionGemmaTrainer(config)\n",
        "\n",
        "print(\"\\n\ud83d\udce5 \u52a0\u8f7d\u6a21\u578b...\")\n",
        "trainer.load_model()\n",
        "print(\"\u2705 \u6a21\u578b\u52a0\u8f7d\u5b8c\u6210\")\n",
        "\n",
        "callbacks = [JupyterVisualizationCallback(update_steps=5)]\n",
        "\n",
        "print(\"\\n\ud83c\udfaf \u5f00\u59cb\u8bad\u7ec3...\")\n",
        "train_result = trainer.train(\n",
        "    train_dataset=dataset,\n",
        "    output_dir=config.logging.output_dir,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "print(f\"\\n\u2705 \u8bad\u7ec3\u5b8c\u6210\uff01\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. \u4fdd\u5b58\u6a21\u578b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = config.logging.output_dir\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"\ud83d\udcbe \u4fdd\u5b58\u6a21\u578b\u5230: {output_dir}\")\n",
        "trainer.save_model(output_dir)\n",
        "\n",
        "config_save_path = Path(output_dir) / 'training_config.yaml'\n",
        "OmegaConf.save(config, config_save_path)\n",
        "print(f\"\u2705 \u914d\u7f6e\u5df2\u4fdd\u5b58\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. \u63a8\u7406\u6d4b\u8bd5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u4ea4\u4e92\u5f0f\u63a8\u7406\n",
        "inference_widget = widgets.Textarea(\n",
        "    value='\u67e5\u8be2\u5317\u4eac\u5929\u6c14',\n",
        "    description='\u8f93\u5165:',\n",
        "    layout=widgets.Layout(width='100%', height='80px')\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(\n",
        "    description='\u8fd0\u884c\u63a8\u7406',\n",
        "    button_style='success',\n",
        "    icon='play'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_run_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        print(\"\ud83e\udd16 \u6b63\u5728\u63a8\u7406...\\n\")\n",
        "        prompt = inference_widget.value\n",
        "        try:\n",
        "            result = trainer.inference(prompt, max_new_tokens=128)\n",
        "            print(f\"\u8f93\u5165: {prompt}\\n\")\n",
        "            print(f\"\u8f93\u51fa: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\u274c \u63a8\u7406\u5931\u8d25: {e}\")\n",
        "\n",
        "run_button.on_click(on_run_button_clicked)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>\ud83c\udfaf \u6a21\u578b\u63a8\u7406\u6d4b\u8bd5</h3>\"),\n",
        "    inference_widget,\n",
        "    run_button,\n",
        "    output_area\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. \u6279\u91cf\u63a8\u7406\u6d4b\u8bd5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_prompts = [\n",
        "    \"\u67e5\u8be2\u5317\u4eac\u5929\u6c14\",\n",
        "    \"\u628a\u80cc\u666f\u6539\u6210\u84dd\u8272\",\n",
        "    \"\u521b\u5efa\u4e00\u4e2a\u540d\u5b57\u53eb\u5f20\u4e09\u7684\u7528\u6237\",\n",
        "]\n",
        "\n",
        "print(\"\ud83e\uddea \u6279\u91cf\u63a8\u7406\u6d4b\u8bd5\\n\")\n",
        "for i, prompt in enumerate(test_prompts, 1):\n",
        "    print(f\"\\n\u6d4b\u8bd5 {i}/{len(test_prompts)}\")\n",
        "    result = trainer.inference(prompt)\n",
        "    print(f\"\u8f93\u5165: {prompt}\")\n",
        "    print(f\"\u8f93\u51fa: {result[:200]}...\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. \u6a21\u578b\u5bfc\u51fa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.export import export_model\n",
        "\n",
        "export_format = widgets.Dropdown(\n",
        "    options=['pytorch', 'gguf'],\n",
        "    value='pytorch',\n",
        "    description='\u683c\u5f0f:'\n",
        ")\n",
        "\n",
        "export_button = widgets.Button(\n",
        "    description='\u5bfc\u51fa\u6a21\u578b',\n",
        "    button_style='primary'\n",
        ")\n",
        "\n",
        "export_output = widgets.Output()\n",
        "\n",
        "def on_export_clicked(b):\n",
        "    with export_output:\n",
        "        clear_output()\n",
        "        print(f\"\ud83d\udce6 \u5bfc\u51fa\u6a21\u578b...\")\n",
        "\n",
        "export_button.on_click(on_export_clicked)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>\ud83d\udce6 \u6a21\u578b\u5bfc\u51fa</h3>\"),\n",
        "    export_format,\n",
        "    export_button,\n",
        "    export_output\n",
        "]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}