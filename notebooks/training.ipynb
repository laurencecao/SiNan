{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ FunctionGemma äº¤äº’å¼è®­ç»ƒ Notebook\n",
        "\n",
        "æœ¬ Notebook æä¾›å¯è§†åŒ–çš„æ¨¡å‹å¾®è°ƒç¯å¢ƒï¼Œæ”¯æŒï¼š\n",
        "- ğŸ“Š å®æ—¶è®­ç»ƒæŒ‡æ ‡å¯è§†åŒ–\n",
        "- ğŸ¯ äº¤äº’å¼å‚æ•°é…ç½®\n",
        "- ğŸ“ˆ Loss æ›²çº¿åŠ¨æ€ç»˜åˆ¶\n",
        "- ğŸ” è®­ç»ƒæ ·æœ¬è´¨é‡æ£€æŸ¥\n",
        "- ğŸ’¾ æ¨¡å‹å¯¼å‡ºä¸æ¨ç†æµ‹è¯•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç¯å¢ƒåˆå§‹åŒ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# è®¾ç½® HF_ENDPOINT ç¯å¢ƒå˜é‡\n",
        "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
        "# æ£€æŸ¥ GPU å¯ç”¨æ€§\n",
        "import torch\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„\n",
        "project_root = Path().absolute().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"ğŸ”¥ PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
        "print(f\"ğŸ® CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸ“º GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"ğŸ’¾ GPU æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ° GPUï¼Œè®­ç»ƒå°†éå¸¸æ…¢\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å¯¼å…¥ä¾èµ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from tqdm.notebook import tqdm\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# é¡¹ç›®æ¨¡å—\n",
        "from src.utils.config_loader import load_config, print_config\n",
        "from src.data_engine.converter import DataConverter\n",
        "from src.data_engine.formatter import FunctionGemmaFormatter\n",
        "from src.training.trainer import FunctionGemmaTrainer\n",
        "from src.training.callbacks import (\n",
        "    WandbCallback,\n",
        "    SampleGenerationCallback,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# è®¾ç½®æ—¥å¿—\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"âœ… æ‰€æœ‰ä¾èµ–å¯¼å…¥æˆåŠŸï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. äº¤äº’å¼å‚æ•°é…ç½®\n",
        "\n",
        "ä½¿ç”¨ä¸‹é¢çš„æ§ä»¶é…ç½®è®­ç»ƒå‚æ•°ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºäº¤äº’å¼é…ç½®æ§ä»¶\n",
        "config_widgets = {\n",
        "    'model_name': widgets.Text(\n",
        "        value='google/functiongemma-270m-it',\n",
        "        description='æ¨¡å‹åç§°:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'max_seq_length': widgets.IntSlider(\n",
        "        value=2048, min=512, max=8192, step=512,\n",
        "        description='æœ€å¤§åºåˆ—é•¿åº¦:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'lora_rank': widgets.IntSlider(\n",
        "        value=16, min=4, max=64, step=4,\n",
        "        description='LoRA Rank:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'lora_alpha': widgets.IntSlider(\n",
        "        value=16, min=4, max=64, step=4,\n",
        "        description='LoRA Alpha:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'epochs': widgets.IntSlider(\n",
        "        value=3, min=1, max=10, step=1,\n",
        "        description='è®­ç»ƒè½®æ•°:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'batch_size': widgets.IntSlider(\n",
        "        value=4, min=1, max=16, step=1,\n",
        "        description='Batch Size:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'learning_rate': widgets.FloatLogSlider(\n",
        "        value=2e-4, base=10, min=-5, max=-3, step=0.1,\n",
        "        description='å­¦ä¹ ç‡:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'gradient_accumulation': widgets.IntSlider(\n",
        "        value=4, min=1, max=16, step=1,\n",
        "        description='æ¢¯åº¦ç´¯ç§¯:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'data_path': widgets.Text(\n",
        "        value='data/processed/train.jsonl',\n",
        "        description='æ•°æ®è·¯å¾„:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "    'output_dir': widgets.Text(\n",
        "        value=f'outputs/models/experiment_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
        "        description='è¾“å‡ºç›®å½•:',\n",
        "        style={'description_width': '150px'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    ),\n",
        "}\n",
        "\n",
        "# æ˜¾ç¤ºé…ç½®æ§ä»¶\n",
        "print(\"ğŸ›ï¸ è®­ç»ƒå‚æ•°é…ç½®\")\n",
        "print(\"=\" * 50)\n",
        "for widget in config_widgets.values():\n",
        "    display(widget)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. æ•°æ®åŠ è½½ä¸å¯è§†åŒ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_visualize_data(data_path: str):\n",
        "    data_path = Path(data_path)\n",
        "    \n",
        "    if not data_path.exists():\n",
        "        print(f\"âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}\")\n",
        "        print(\"æ­£åœ¨åˆ›å»ºç¤ºä¾‹æ•°æ®...\")\n",
        "        create_sample_data(data_path)\n",
        "    \n",
        "    converter = DataConverter()\n",
        "    dataset = converter.load_dataset(str(data_path))\n",
        "    df = pd.DataFrame(dataset)\n",
        "    \n",
        "    print(f\"\\nğŸ“Š æ•°æ®æ¦‚è§ˆ\")\n",
        "    print(f\"æ€»æ ·æœ¬æ•°: {len(df)}\")\n",
        "    print(f\"åˆ—å: {list(df.columns)}\")\n",
        "    \n",
        "    print(\"\\nğŸ“‹ å‰ 3 æ¡æ ·æœ¬:\")\n",
        "    for i in range(min(3, len(df))):\n",
        "        print(f\"\\næ ·æœ¬ {i+1}:\")\n",
        "        for col in df.columns:\n",
        "            value = df.iloc[i][col]\n",
        "            if isinstance(value, str) and len(value) > 200:\n",
        "                value = value[:200] + \"...\"\n",
        "            print(f\"  {col}: {value}\")\n",
        "    \n",
        "    return dataset, df\n",
        "\n",
        "def create_sample_data(output_path: Path):\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    sample_data = [\n",
        "        {\"text\": \"Sample training text 1\"},\n",
        "        {\"text\": \"Sample training text 2\"},\n",
        "        {\"text\": \"Sample training text 3\"},\n",
        "    ]\n",
        "    \n",
        "    expanded_data = []\n",
        "    for i in range(100):\n",
        "        for sample in sample_data:\n",
        "            expanded_data.append(sample)\n",
        "    \n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for item in expanded_data:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "    \n",
        "    print(f\"âœ… å·²åˆ›å»ºç¤ºä¾‹æ•°æ®: {output_path}\")\n",
        "\n",
        "# åŠ è½½æ•°æ®\n",
        "data_path = config_widgets['data_path'].value\n",
        "dataset, df = load_and_visualize_data(data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. æ•°æ®ç»Ÿè®¡åˆ†æ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ•°æ®ç»Ÿè®¡å¯è§†åŒ–\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "if 'text' in df.columns:\n",
        "    text_lengths = df['text'].str.len()\n",
        "    axes[0].hist(text_lengths, bins=30, edgecolor='black', alpha=0.7)\n",
        "    axes[0].set_xlabel('Text Length')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title('Distribution of Text Length')\n",
        "    axes[0].axvline(text_lengths.mean(), color='red', linestyle='--')\n",
        "\n",
        "if 'tool_name' in df.columns:\n",
        "    tool_counts = df['tool_name'].value_counts()\n",
        "    tool_counts.plot(kind='bar', ax=axes[1])\n",
        "    axes[1].set_title('Tool Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nğŸ“ˆ æ•°æ®ç»Ÿè®¡\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. è®­ç»ƒå¯è§†åŒ–å›è°ƒç±»"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "from collections import defaultdict\n",
        "\n",
        "class JupyterVisualizationCallback(TrainerCallback):\n",
        "    def __init__(self, update_steps: int = 10):\n",
        "        super().__init__()\n",
        "        self.update_steps = update_steps\n",
        "        self.metrics_history = defaultdict(list)\n",
        "        self.fig = None\n",
        "        self.axes = None\n",
        "    \n",
        "    def setup_plot(self):\n",
        "        plt.ion()\n",
        "        self.fig, self.axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "        self.fig.suptitle('Training Metrics (Real-time)', fontsize=14)\n",
        "        plt.show()\n",
        "    \n",
        "    def on_train_begin(self, args, state, control, **kwargs):\n",
        "        print(\"\\nğŸš€ è®­ç»ƒå¼€å§‹ï¼\")\n",
        "        self.setup_plot()\n",
        "    \n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is None:\n",
        "            return\n",
        "        step = state.global_step\n",
        "        for key, value in logs.items():\n",
        "            if isinstance(value, (int, float)):\n",
        "                self.metrics_history[key].append((step, value))\n",
        "        if step % self.update_steps == 0:\n",
        "            self.update_plots()\n",
        "    \n",
        "    def update_plots(self):\n",
        "        if self.axes is None:\n",
        "            return\n",
        "        for ax in self.axes.flat:\n",
        "            ax.clear()\n",
        "        \n",
        "        if 'loss' in self.metrics_history:\n",
        "            steps, losses = zip(*self.metrics_history['loss'])\n",
        "            self.axes[0, 0].plot(steps, losses, 'b-', linewidth=2)\n",
        "            self.axes[0, 0].set_title('Training Loss')\n",
        "            self.axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        self.fig.canvas.draw()\n",
        "        self.fig.canvas.flush_events()\n",
        "        plt.pause(0.01)\n",
        "    \n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")\n",
        "        plt.ioff()\n",
        "        plt.savefig('training_metrics.png', dpi=150)\n",
        "\n",
        "print(\"âœ… å¯è§†åŒ–å›è°ƒç±»å·²å®šä¹‰\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. å¼€å§‹è®­ç»ƒ\n",
        "\n",
        "è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼å¼€å§‹è®­ç»ƒï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from omegaconf import OmegaConf\n",
        "\n",
        "config_dict = {\n",
        "    'model': {\n",
        "        'name': config_widgets['model_name'].value,\n",
        "        'max_seq_length': config_widgets['max_seq_length'].value,\n",
        "        'dtype': 'bfloat16',\n",
        "        'lora': {\n",
        "            'enabled': True,\n",
        "            'rank': config_widgets['lora_rank'].value,\n",
        "            'alpha': config_widgets['lora_alpha'].value,\n",
        "            'target_modules': [\"q_proj\", \"k_proj\", \"v_proj\"],\n",
        "        },\n",
        "    },\n",
        "    'training': {\n",
        "        'epochs': config_widgets['epochs'].value,\n",
        "        'per_device_train_batch_size': config_widgets['batch_size'].value,\n",
        "        'learning_rate': config_widgets['learning_rate'].value,\n",
        "    },\n",
        "    'logging': {\n",
        "        'output_dir': config_widgets['output_dir'].value,\n",
        "        'wandb': {'enabled': False}\n",
        "    }\n",
        "}\n",
        "\n",
        "config = OmegaConf.create(config_dict)\n",
        "print(\"ğŸ”§ è®­ç»ƒé…ç½®\")\n",
        "print(OmegaConf.to_yaml(config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºè®­ç»ƒå™¨\n",
        "trainer = FunctionGemmaTrainer(config)\n",
        "\n",
        "print(\"\\nğŸ“¥ åŠ è½½æ¨¡å‹...\")\n",
        "trainer.load_model()\n",
        "print(\"âœ… æ¨¡å‹åŠ è½½å®Œæˆ\")\n",
        "\n",
        "callbacks = [JupyterVisualizationCallback(update_steps=5)]\n",
        "\n",
        "print(\"\\nğŸ¯ å¼€å§‹è®­ç»ƒ...\")\n",
        "train_result = trainer.train(\n",
        "    train_dataset=dataset,\n",
        "    output_dir=config.logging.output_dir,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "print(f\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ä¿å­˜æ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = config.logging.output_dir\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ’¾ ä¿å­˜æ¨¡å‹åˆ°: {output_dir}\")\n",
        "trainer.save_model(output_dir)\n",
        "\n",
        "config_save_path = Path(output_dir) / 'training_config.yaml'\n",
        "OmegaConf.save(config, config_save_path)\n",
        "print(f\"âœ… é…ç½®å·²ä¿å­˜\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. æ¨ç†æµ‹è¯•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# äº¤äº’å¼æ¨ç†\n",
        "inference_widget = widgets.Textarea(\n",
        "    value='æŸ¥è¯¢åŒ—äº¬å¤©æ°”',\n",
        "    description='è¾“å…¥:',\n",
        "    layout=widgets.Layout(width='100%', height='80px')\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(\n",
        "    description='è¿è¡Œæ¨ç†',\n",
        "    button_style='success',\n",
        "    icon='play'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_run_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        print(\"ğŸ¤– æ­£åœ¨æ¨ç†...\\n\")\n",
        "        prompt = inference_widget.value\n",
        "        try:\n",
        "            result = trainer.inference(prompt, max_new_tokens=128)\n",
        "            print(f\"è¾“å…¥: {prompt}\\n\")\n",
        "            print(f\"è¾“å‡º: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ æ¨ç†å¤±è´¥: {e}\")\n",
        "\n",
        "run_button.on_click(on_run_button_clicked)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>ğŸ¯ æ¨¡å‹æ¨ç†æµ‹è¯•</h3>\"),\n",
        "    inference_widget,\n",
        "    run_button,\n",
        "    output_area\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. æ‰¹é‡æ¨ç†æµ‹è¯•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_prompts = [\n",
        "    \"æŸ¥è¯¢åŒ—äº¬å¤©æ°”\",\n",
        "    \"æŠŠèƒŒæ™¯æ”¹æˆè“è‰²\",\n",
        "    \"åˆ›å»ºä¸€ä¸ªåå­—å«å¼ ä¸‰çš„ç”¨æˆ·\",\n",
        "]\n",
        "\n",
        "print(\"ğŸ§ª æ‰¹é‡æ¨ç†æµ‹è¯•\\n\")\n",
        "for i, prompt in enumerate(test_prompts, 1):\n",
        "    print(f\"\\næµ‹è¯• {i}/{len(test_prompts)}\")\n",
        "    result = trainer.inference(prompt)\n",
        "    print(f\"è¾“å…¥: {prompt}\")\n",
        "    print(f\"è¾“å‡º: {result[:200]}...\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. æ¨¡å‹å¯¼å‡º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.export import export_model\n",
        "\n",
        "export_format = widgets.Dropdown(\n",
        "    options=['pytorch', 'gguf'],\n",
        "    value='pytorch',\n",
        "    description='æ ¼å¼:'\n",
        ")\n",
        "\n",
        "export_button = widgets.Button(\n",
        "    description='å¯¼å‡ºæ¨¡å‹',\n",
        "    button_style='primary'\n",
        ")\n",
        "\n",
        "export_output = widgets.Output()\n",
        "\n",
        "def on_export_clicked(b):\n",
        "    with export_output:\n",
        "        clear_output()\n",
        "        print(f\"ğŸ“¦ å¯¼å‡ºæ¨¡å‹...\")\n",
        "\n",
        "export_button.on_click(on_export_clicked)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>ğŸ“¦ æ¨¡å‹å¯¼å‡º</h3>\"),\n",
        "    export_format,\n",
        "    export_button,\n",
        "    export_output\n",
        "]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
